{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1 - Dataset e Regressão Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dummy_classifier.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurando options do pandas para visualização\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atributo_0</th>\n",
       "      <th>atributo_1</th>\n",
       "      <th>atributo_2</th>\n",
       "      <th>atributo_3</th>\n",
       "      <th>atributo_4</th>\n",
       "      <th>atributo_5</th>\n",
       "      <th>atributo_6</th>\n",
       "      <th>atributo_7</th>\n",
       "      <th>atributo_8</th>\n",
       "      <th>atributo_9</th>\n",
       "      <th>atributo_10</th>\n",
       "      <th>atributo_11</th>\n",
       "      <th>atributo_12</th>\n",
       "      <th>atributo_13</th>\n",
       "      <th>atributo_14</th>\n",
       "      <th>atributo_15</th>\n",
       "      <th>atributo_16</th>\n",
       "      <th>atributo_17</th>\n",
       "      <th>atributo_18</th>\n",
       "      <th>atributo_19</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-0.001655</td>\n",
       "      <td>0.689755</td>\n",
       "      <td>0.026827</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>-0.553105</td>\n",
       "      <td>-0.174038</td>\n",
       "      <td>0.757099</td>\n",
       "      <td>0.004873</td>\n",
       "      <td>-0.006979</td>\n",
       "      <td>0.003128</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>-0.555636</td>\n",
       "      <td>-0.138944</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.670982</td>\n",
       "      <td>0.002670</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>-0.000826</td>\n",
       "      <td>0.499660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.998075</td>\n",
       "      <td>1.571259</td>\n",
       "      <td>0.969300</td>\n",
       "      <td>0.998874</td>\n",
       "      <td>1.346625</td>\n",
       "      <td>0.687293</td>\n",
       "      <td>1.154179</td>\n",
       "      <td>0.995161</td>\n",
       "      <td>1.001194</td>\n",
       "      <td>1.225768</td>\n",
       "      <td>1.002002</td>\n",
       "      <td>1.191804</td>\n",
       "      <td>0.254846</td>\n",
       "      <td>1.071434</td>\n",
       "      <td>1.422104</td>\n",
       "      <td>1.086119</td>\n",
       "      <td>0.998939</td>\n",
       "      <td>1.026308</td>\n",
       "      <td>0.998737</td>\n",
       "      <td>0.998167</td>\n",
       "      <td>0.500002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-4.200454</td>\n",
       "      <td>-6.782857</td>\n",
       "      <td>-4.232569</td>\n",
       "      <td>-4.898426</td>\n",
       "      <td>-8.717279</td>\n",
       "      <td>-3.855368</td>\n",
       "      <td>-5.270061</td>\n",
       "      <td>-4.626742</td>\n",
       "      <td>-4.165448</td>\n",
       "      <td>-5.782206</td>\n",
       "      <td>-4.374984</td>\n",
       "      <td>-6.571926</td>\n",
       "      <td>-1.718474</td>\n",
       "      <td>-5.235896</td>\n",
       "      <td>-6.245018</td>\n",
       "      <td>-4.463408</td>\n",
       "      <td>-4.070195</td>\n",
       "      <td>-3.746395</td>\n",
       "      <td>-4.124820</td>\n",
       "      <td>-4.203595</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-0.678320</td>\n",
       "      <td>-0.277793</td>\n",
       "      <td>-0.680518</td>\n",
       "      <td>-0.670271</td>\n",
       "      <td>-1.370721</td>\n",
       "      <td>-0.671095</td>\n",
       "      <td>0.044893</td>\n",
       "      <td>-0.666985</td>\n",
       "      <td>-0.677943</td>\n",
       "      <td>-0.815451</td>\n",
       "      <td>-0.675081</td>\n",
       "      <td>-1.175774</td>\n",
       "      <td>-0.288409</td>\n",
       "      <td>-0.813784</td>\n",
       "      <td>-0.150797</td>\n",
       "      <td>-0.802678</td>\n",
       "      <td>-0.666931</td>\n",
       "      <td>-0.148389</td>\n",
       "      <td>-0.668469</td>\n",
       "      <td>-0.675472</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.004886</td>\n",
       "      <td>0.338261</td>\n",
       "      <td>0.049479</td>\n",
       "      <td>-0.003572</td>\n",
       "      <td>-0.613865</td>\n",
       "      <td>-0.253863</td>\n",
       "      <td>0.755547</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>-0.005543</td>\n",
       "      <td>0.119722</td>\n",
       "      <td>0.005905</td>\n",
       "      <td>-0.538234</td>\n",
       "      <td>-0.182211</td>\n",
       "      <td>-0.106984</td>\n",
       "      <td>0.708761</td>\n",
       "      <td>-0.063542</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>0.627298</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.671452</td>\n",
       "      <td>1.695891</td>\n",
       "      <td>0.712041</td>\n",
       "      <td>0.676975</td>\n",
       "      <td>0.250927</td>\n",
       "      <td>0.284476</td>\n",
       "      <td>1.463504</td>\n",
       "      <td>0.680065</td>\n",
       "      <td>0.669644</td>\n",
       "      <td>0.887736</td>\n",
       "      <td>0.679879</td>\n",
       "      <td>0.123480</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.554460</td>\n",
       "      <td>1.504331</td>\n",
       "      <td>0.792885</td>\n",
       "      <td>0.676747</td>\n",
       "      <td>1.206889</td>\n",
       "      <td>0.676669</td>\n",
       "      <td>0.677282</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>4.126287</td>\n",
       "      <td>8.989170</td>\n",
       "      <td>4.181215</td>\n",
       "      <td>4.291108</td>\n",
       "      <td>5.981073</td>\n",
       "      <td>2.994331</td>\n",
       "      <td>7.562854</td>\n",
       "      <td>5.213360</td>\n",
       "      <td>4.704046</td>\n",
       "      <td>4.805290</td>\n",
       "      <td>4.707000</td>\n",
       "      <td>4.827852</td>\n",
       "      <td>1.192039</td>\n",
       "      <td>3.587969</td>\n",
       "      <td>9.493749</td>\n",
       "      <td>4.989388</td>\n",
       "      <td>4.277918</td>\n",
       "      <td>5.757004</td>\n",
       "      <td>3.952875</td>\n",
       "      <td>4.670688</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          atributo_0     atributo_1     atributo_2     atributo_3  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean       -0.001655       0.689755       0.026827       0.001320   \n",
       "std         0.998075       1.571259       0.969300       0.998874   \n",
       "min        -4.200454      -6.782857      -4.232569      -4.898426   \n",
       "25%        -0.678320      -0.277793      -0.680518      -0.670271   \n",
       "50%         0.004886       0.338261       0.049479      -0.003572   \n",
       "75%         0.671452       1.695891       0.712041       0.676975   \n",
       "max         4.126287       8.989170       4.181215       4.291108   \n",
       "\n",
       "          atributo_4     atributo_5     atributo_6     atributo_7  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean       -0.553105      -0.174038       0.757099       0.004873   \n",
       "std         1.346625       0.687293       1.154179       0.995161   \n",
       "min        -8.717279      -3.855368      -5.270061      -4.626742   \n",
       "25%        -1.370721      -0.671095       0.044893      -0.666985   \n",
       "50%        -0.613865      -0.253863       0.755547       0.005094   \n",
       "75%         0.250927       0.284476       1.463504       0.680065   \n",
       "max         5.981073       2.994331       7.562854       5.213360   \n",
       "\n",
       "          atributo_8     atributo_9    atributo_10    atributo_11  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean       -0.006979       0.003128       0.002217      -0.555636   \n",
       "std         1.001194       1.225768       1.002002       1.191804   \n",
       "min        -4.165448      -5.782206      -4.374984      -6.571926   \n",
       "25%        -0.677943      -0.815451      -0.675081      -1.175774   \n",
       "50%        -0.005543       0.119722       0.005905      -0.538234   \n",
       "75%         0.669644       0.887736       0.679879       0.123480   \n",
       "max         4.704046       4.805290       4.707000       4.827852   \n",
       "\n",
       "         atributo_12    atributo_13    atributo_14    atributo_15  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean       -0.138944      -0.187500       0.670982       0.002670   \n",
       "std         0.254846       1.071434       1.422104       1.086119   \n",
       "min        -1.718474      -5.235896      -6.245018      -4.463408   \n",
       "25%        -0.288409      -0.813784      -0.150797      -0.802678   \n",
       "50%        -0.182211      -0.106984       0.708761      -0.063542   \n",
       "75%         0.002239       0.554460       1.504331       0.792885   \n",
       "max         1.192039       3.587969       9.493749       4.989388   \n",
       "\n",
       "         atributo_16    atributo_17    atributo_18    atributo_19  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean        0.004270       0.561383       0.002828      -0.000826   \n",
       "std         0.998939       1.026308       0.998737       0.998167   \n",
       "min        -4.070195      -3.746395      -4.124820      -4.203595   \n",
       "25%        -0.666931      -0.148389      -0.668469      -0.675472   \n",
       "50%         0.004211       0.627298       0.000173       0.000518   \n",
       "75%         0.676747       1.206889       0.676669       0.677282   \n",
       "max         4.277918       5.757004       3.952875       4.670688   \n",
       "\n",
       "              target  \n",
       "count  100000.000000  \n",
       "mean        0.499660  \n",
       "std         0.500002  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         1.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vamos comecar olhando descritivas da base, vamos notar que se trata de um dado complexo, com pouco contexto\n",
    "#Esse tipo de dado é complexo para uma pessoa observar e encontrar padrões, por isso modelamos a informação\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    50034\n",
       "1.0    49966\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando dos dados em conjuntos de treino e teste\n",
    "Vamos dividir nossos dados em dois conjuntos: Treino e Teste.\n",
    "Esse processo é importante para validarmos o processo de modelagem: \n",
    "- Treinamos utilizando o conjunto de <b>Treino</b>\n",
    "- Verificamos as metricas de interesse no conjunto de <b>Teste</b>\n",
    "- Podemos verificar as metricas também no conjunto de Treino com o objetivo de diagnosticar <i>overfitting</i>\n",
    "\n",
    "Para essa separação, podemos utilizar regras simples, como 80% dos dados para treino e 20% para teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop([\"target\"],axis=1), #Removemos a target do conjunto de Treino\n",
    "                                                   df[\"target\"],# Target\n",
    "                                                   test_size = 0.2 #Costumamos usar regras simples, como 80% treino e 20% teste\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 20) (80000,) (20000, 20) (20000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento dos modelos\n",
    "Utilizaremos o pacote [sklearn](https://scikit-learn.org/stable/) para realizar o treinamento e cálculo das métricas de avaliação.\n",
    "\n",
    "Utilizar esse pacote nos permite seguir uma padronização, que torna a sintaxe bem simples:\n",
    "- .fit(X,y) realiza o treino do modelo\n",
    "- .predict(X) faz a predição do modelo. Em modelos de classificação, a saída será discreta (ex: 0 ou 1)\n",
    "- .predict_proba(X) faz a predição do modelo de forma contínua, ou seja, a probabilidade de pertencer a cada uma das classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Modelo simples utilizando Regressão Logistica\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train) #Treina o modelo\n",
    "\n",
    "train_performance = lr.predict(X_train)\n",
    "test_performance = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Os hyperparametros da Regressão Logistica\n",
    "- C: Força da regularização, é uma estratégia utilizada para fazer com que o modelo se ajuste menos ao conjunto de treino e consiga generalizar melhor.\n",
    "- penalty: Tipo de regularização. Pode ser l1, l2 ou elastic\n",
    "Para mais informações, recomendo a leitura da [documentação](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando o classification_report para medir performance\n",
    "O método classification_report(y_verdadeiro, y_predito) recebe a predição do modelo (discreta) e os valores reais referentes a essa predição. Com esses valores, conseguimos calcular:\n",
    "- Precision (Precisão): Classificados positivo (1) e realmente positivos, dividido pela quantidade de positivos previstos (o quão bem eu acerto quem eu classifico como positivo?)\n",
    "- Recall (Revocação): Classificados positivo (1) e realmente positivos, dividido pelo total de positivos (Quantos positivos eu acerto no total?)\n",
    "- f1-score: Forma de agregar precisão e recall.\n",
    "\n",
    "Quando vamos calcular essas métricas, devemos definir o que é o positivo para nós. No caso de classificação, costumamos falar que o positivo é quem realiza nosso evento, ou seja, marcados como 1. Utilizando essa perspectiva, devemos observar a linha referente a classe 1 na nossa classification report.\n",
    "\n",
    "Nota: Nada impede de mudarmos o referencial e chamar o positivo de 0, os calculos poderão ser feitos da mesma forma, porém a interpretação será diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.75      0.76     39995\n",
      "         1.0       0.76      0.78      0.77     40005\n",
      "\n",
      "    accuracy                           0.76     80000\n",
      "   macro avg       0.76      0.76      0.76     80000\n",
      "weighted avg       0.76      0.76      0.76     80000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, train_performance)) #Medimos a performance no treino para bsucar overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.74      0.75     10039\n",
      "         1.0       0.75      0.78      0.76      9961\n",
      "\n",
      "    accuracy                           0.76     20000\n",
      "   macro avg       0.76      0.76      0.76     20000\n",
      "weighted avg       0.76      0.76      0.76     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Medimos a performance no teste. Essa é a que vale, pois são dados desconhecidos pelo modelo\n",
    "print(classification_report(y_test, test_performance)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2 - Modelos de Árvore e Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo em árvore, note o padrão sklearn torna a sintaxe semelhante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train,y_train)\n",
    "\n",
    "train_performance = tree.predict(X_train)\n",
    "test_performance = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Os hyperparametros do modelo de árvore:\n",
    "- criterion: Função que mede a qualidade de uma determinado corte de atributos, ou seja, o quão bem a minha regra de decisão separa minhas classes\n",
    "- max_depth: Produndidade máxima da árvore\n",
    "- min_samples_leaf: Mínimo de amostras para um nó folha.\n",
    "    \n",
    "Para mais informações sobre o modelo de árvore, recomendo a leitura da [documentação](https://scikit-learn.org/stable/modules/tree.html#tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     39995\n",
      "         1.0       1.00      1.00      1.00     40005\n",
      "\n",
      "    accuracy                           1.00     80000\n",
      "   macro avg       1.00      1.00      1.00     80000\n",
      "weighted avg       1.00      1.00      1.00     80000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, train_performance)) #Sinal de overfitting!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.74      0.74     10039\n",
      "         1.0       0.74      0.74      0.74      9961\n",
      "\n",
      "    accuracy                           0.74     20000\n",
      "   macro avg       0.74      0.74      0.74     20000\n",
      "weighted avg       0.74      0.74      0.74     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_performance)) #Sinal de overfitting!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "train_performance = rf.predict(X_train)\n",
    "test_performance = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Os hyperparametros do modelo de árvore:\n",
    "- criterion: Função que mede a qualidade de uma determinado corte de atributos, ou seja, o quão bem a minha regra de decisão separa minhas classes\n",
    "- max_depth: Produndidade máxima da árvore\n",
    "- min_samples_leaf: Mínimo de amostras para um nó folha.\n",
    "- n_estimators: Quantidade de árvores criadas para a floresta\n",
    "- bootstrap: Realizar amostragem com reposição. É importante manter em True para criarmos árvores diferentes umas das outras.\n",
    "    \n",
    "Para mais informações sobre o modelo de Floresta Aleatória, recomendo a leitura da [documentação](https://scikit-learn.org/stable/modules/ensemble.html#forest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98     39995\n",
      "         1.0       0.99      0.98      0.98     40005\n",
      "\n",
      "    accuracy                           0.98     80000\n",
      "   macro avg       0.98      0.98      0.98     80000\n",
      "weighted avg       0.98      0.98      0.98     80000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, train_performance)) #Sinal de Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.85      0.84     10039\n",
      "         1.0       0.84      0.82      0.83      9961\n",
      "\n",
      "    accuracy                           0.83     20000\n",
      "   macro avg       0.83      0.83      0.83     20000\n",
      "weighted avg       0.83      0.83      0.83     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_performance)) #Sinal de Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 3 - Ajustando Hyperparametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lidando com Overfitting - Ajuste de Hyperparametros\n",
    "Uma forma comum de lidar com <i>overfitting</i> é ajustando os hyperparametros de forma que controlemos o quanto o modelo consegue se ajustar em nossos dados.\n",
    "\n",
    "O <i>overfitting</i> normalmente é causado por uma complexidade do modelo, em modelos de árvore isso quer dizer:\n",
    "- Muitos estimadores (muitas árvores): Em modelos de ensemble, adicionar muitos modelos pode não agregar na previsão resultante. Muitos modelos identicos podem gerar um viés e causar <i>overfitting</i>\n",
    "- Árvores muito profundas: Cada nível de profundidade da árvore cria uma regra nova para separar nossos dados, ou seja, cada folha possui menos amostras a cada nível que crescemos a árvore. Sendo assim, em treino, regras que afetam poucas amostras são muito especificas, portanto podem estar muito vínculadas ao conjunto de treino e não generalizar.\n",
    "\n",
    "Uma forma comum de fazer a busca dos melhores hyperparametros é através do Grid Search (Busca em grade).\n",
    "- Montamos uma grade contendo os hyperparametros de interesse e os respectivos valores.\n",
    "- O algoritmo vai separar a nossa base em \"mini conjuntos\" de treino e teste para testar cada combinação da grade\n",
    "- A melhor combinação (a que maximizar o acerto) será a escolhida.\n",
    "\n",
    "Exemplo: Vamos testar uma RandomForest com 10 e 20 árvores, onde cada árvore pode ter profundidade máxima de 3 ou 4. Sendo assim, temos:\n",
    "\n",
    "|iteração|árvores|profundidade|\n",
    "| ------------- |:-------------:| -----:|\n",
    "|1|10|3|\n",
    "|2|20|3|\n",
    "|3|10|4|\n",
    "|4|20|4|\n",
    "\n",
    "Supondo que vamos separar nossos dados em 3 subconjuntos A, B e C para testar cada combinação:\n",
    "Na iteração 1 teremos\n",
    "\n",
    "|Conjunto de treino|Conjunto de Teste|Acerto (%)|\n",
    "| ------------- |:-------------:| -----:|\n",
    "|A+B|C|80|\n",
    "|A+C|B|90|\n",
    "|B+C|A|95|\n",
    "\n",
    "Sendo assim, essa estratégia da iteração 1 possui um acerto médio de 88.3%. Repetimos o processo até encontrar a melhor combinação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 20)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] max_depth=2, n_estimators=5 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... max_depth=2, n_estimators=5, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=5 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... max_depth=2, n_estimators=5, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=5, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=10, total=   0.4s\n",
      "[CV] max_depth=2, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=10, total=   0.4s\n",
      "[CV] max_depth=2, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=10, total=   0.4s\n",
      "[CV] max_depth=2, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=20, total=   0.8s\n",
      "[CV] max_depth=2, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=20, total=   0.8s\n",
      "[CV] max_depth=2, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=20, total=   0.8s\n",
      "[CV] max_depth=3, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=5, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=5, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=5, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=10, total=   0.5s\n",
      "[CV] max_depth=3, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=10, total=   0.6s\n",
      "[CV] max_depth=3, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=10, total=   0.5s\n",
      "[CV] max_depth=3, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=20, total=   1.2s\n",
      "[CV] max_depth=3, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=20, total=   1.0s\n",
      "[CV] max_depth=3, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=20, total=   1.0s\n",
      "[CV] max_depth=4, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=5, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=5, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=5, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=10, total=   0.6s\n",
      "[CV] max_depth=4, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=10, total=   0.6s\n",
      "[CV] max_depth=4, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=10, total=   0.6s\n",
      "[CV] max_depth=4, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=20, total=   1.2s\n",
      "[CV] max_depth=4, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=20, total=   1.2s\n",
      "[CV] max_depth=4, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=20, total=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   16.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=10, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [2, 3, 4], 'n_estimators': [5, 10, 20]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_rf = {\n",
    "            \"n_estimators\":[5,10,20], #Regular o número de estimadores\n",
    "            \"max_depth\":[2,3,4] #Regular a profundidade das árvores\n",
    "          }\n",
    "gs = GridSearchCV(rf, #Objeto do classificador sklearn\n",
    "                  param_grid = dict_rf, #Dicionario de hyperparametros\n",
    "                  cv = 3, #Validação cruzada - vezes que o algoritmo vai separar o nosso dado e testar\n",
    "                  verbose = 2 #Apenas para vermos o que está acontecendo (print de textos na tela)\n",
    "                 )\n",
    "\n",
    "gs.fit(X_train,y_train) #Fit do objeto GS, uma RF será treinada com cada uma das combinações de hyperparametros do dicionario para cada valor do CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gs = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=20,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_performance = rf_gs.predict(X_test)\n",
    "train_performance = rf_gs.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.78      0.80     39995\n",
      "         1.0       0.79      0.82      0.81     40005\n",
      "\n",
      "    accuracy                           0.80     80000\n",
      "   macro avg       0.80      0.80      0.80     80000\n",
      "weighted avg       0.80      0.80      0.80     80000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, train_performance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.77      0.79     10039\n",
      "         1.0       0.78      0.82      0.80      9961\n",
      "\n",
      "    accuracy                           0.79     20000\n",
      "   macro avg       0.79      0.79      0.79     20000\n",
      "weighted avg       0.79      0.79      0.79     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_performance)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 4 - Formas de aplicar um modelo de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83099904 0.16900096]\n",
      " [0.84400216 0.15599784]\n",
      " [0.28592926 0.71407074]\n",
      " ...\n",
      " [0.58031645 0.41968355]\n",
      " [0.6637815  0.3362185 ]\n",
      " [0.81879734 0.18120266]]\n"
     ]
    }
   ],
   "source": [
    "predict_proba_rf = rf_gs.predict_proba(X_test)\n",
    "print(predict_proba_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"predict_proba\"] = predict_proba_rf[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"target\"] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atributo_0</th>\n",
       "      <th>atributo_1</th>\n",
       "      <th>atributo_2</th>\n",
       "      <th>atributo_3</th>\n",
       "      <th>atributo_4</th>\n",
       "      <th>atributo_5</th>\n",
       "      <th>atributo_6</th>\n",
       "      <th>atributo_7</th>\n",
       "      <th>atributo_8</th>\n",
       "      <th>atributo_9</th>\n",
       "      <th>atributo_10</th>\n",
       "      <th>atributo_11</th>\n",
       "      <th>atributo_12</th>\n",
       "      <th>atributo_13</th>\n",
       "      <th>atributo_14</th>\n",
       "      <th>atributo_15</th>\n",
       "      <th>atributo_16</th>\n",
       "      <th>atributo_17</th>\n",
       "      <th>atributo_18</th>\n",
       "      <th>atributo_19</th>\n",
       "      <th>predict_proba</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>97320</td>\n",
       "      <td>-0.767145</td>\n",
       "      <td>-0.333025</td>\n",
       "      <td>-0.584866</td>\n",
       "      <td>1.770461</td>\n",
       "      <td>-0.099363</td>\n",
       "      <td>-0.115322</td>\n",
       "      <td>0.295570</td>\n",
       "      <td>0.500035</td>\n",
       "      <td>-0.588367</td>\n",
       "      <td>-0.312699</td>\n",
       "      <td>-0.088776</td>\n",
       "      <td>-0.902230</td>\n",
       "      <td>-0.094666</td>\n",
       "      <td>-0.707977</td>\n",
       "      <td>0.163998</td>\n",
       "      <td>0.619729</td>\n",
       "      <td>-0.328969</td>\n",
       "      <td>0.460496</td>\n",
       "      <td>-0.365602</td>\n",
       "      <td>-0.643339</td>\n",
       "      <td>0.169001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68107</td>\n",
       "      <td>-0.924253</td>\n",
       "      <td>-4.220112</td>\n",
       "      <td>-2.718203</td>\n",
       "      <td>1.081076</td>\n",
       "      <td>0.120575</td>\n",
       "      <td>-0.940722</td>\n",
       "      <td>-1.600090</td>\n",
       "      <td>-1.015530</td>\n",
       "      <td>-1.847722</td>\n",
       "      <td>0.874642</td>\n",
       "      <td>0.937930</td>\n",
       "      <td>-1.262193</td>\n",
       "      <td>-0.073119</td>\n",
       "      <td>-1.271775</td>\n",
       "      <td>-0.481876</td>\n",
       "      <td>3.446100</td>\n",
       "      <td>0.247052</td>\n",
       "      <td>-1.895841</td>\n",
       "      <td>0.280185</td>\n",
       "      <td>0.953621</td>\n",
       "      <td>0.155998</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59450</td>\n",
       "      <td>-0.162510</td>\n",
       "      <td>3.065559</td>\n",
       "      <td>1.049427</td>\n",
       "      <td>0.560586</td>\n",
       "      <td>-2.530358</td>\n",
       "      <td>-0.907176</td>\n",
       "      <td>2.322294</td>\n",
       "      <td>-0.901188</td>\n",
       "      <td>-0.134448</td>\n",
       "      <td>1.457613</td>\n",
       "      <td>-0.522467</td>\n",
       "      <td>-0.333502</td>\n",
       "      <td>-0.436918</td>\n",
       "      <td>0.936369</td>\n",
       "      <td>2.781460</td>\n",
       "      <td>-0.715270</td>\n",
       "      <td>-0.105945</td>\n",
       "      <td>0.595663</td>\n",
       "      <td>0.704110</td>\n",
       "      <td>-1.123141</td>\n",
       "      <td>0.714071</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29422</td>\n",
       "      <td>-0.576252</td>\n",
       "      <td>0.604844</td>\n",
       "      <td>0.285657</td>\n",
       "      <td>-0.191600</td>\n",
       "      <td>-0.726441</td>\n",
       "      <td>-0.341828</td>\n",
       "      <td>0.380920</td>\n",
       "      <td>-1.480858</td>\n",
       "      <td>0.122126</td>\n",
       "      <td>0.719870</td>\n",
       "      <td>-0.003143</td>\n",
       "      <td>0.191535</td>\n",
       "      <td>-0.098238</td>\n",
       "      <td>0.490150</td>\n",
       "      <td>0.728078</td>\n",
       "      <td>-0.108936</td>\n",
       "      <td>-0.746725</td>\n",
       "      <td>-0.277786</td>\n",
       "      <td>0.363014</td>\n",
       "      <td>1.634629</td>\n",
       "      <td>0.643472</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77971</td>\n",
       "      <td>0.321697</td>\n",
       "      <td>2.912722</td>\n",
       "      <td>0.786751</td>\n",
       "      <td>2.671572</td>\n",
       "      <td>-2.019777</td>\n",
       "      <td>-0.579406</td>\n",
       "      <td>2.424262</td>\n",
       "      <td>-0.345002</td>\n",
       "      <td>0.549287</td>\n",
       "      <td>0.541856</td>\n",
       "      <td>0.810591</td>\n",
       "      <td>-0.927847</td>\n",
       "      <td>-0.410535</td>\n",
       "      <td>0.229986</td>\n",
       "      <td>2.361430</td>\n",
       "      <td>-0.671067</td>\n",
       "      <td>-0.511379</td>\n",
       "      <td>1.386439</td>\n",
       "      <td>-1.604733</td>\n",
       "      <td>-1.292449</td>\n",
       "      <td>0.667288</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       atributo_0  atributo_1  atributo_2  atributo_3  atributo_4  atributo_5  \\\n",
       "97320   -0.767145   -0.333025   -0.584866    1.770461   -0.099363   -0.115322   \n",
       "68107   -0.924253   -4.220112   -2.718203    1.081076    0.120575   -0.940722   \n",
       "59450   -0.162510    3.065559    1.049427    0.560586   -2.530358   -0.907176   \n",
       "29422   -0.576252    0.604844    0.285657   -0.191600   -0.726441   -0.341828   \n",
       "77971    0.321697    2.912722    0.786751    2.671572   -2.019777   -0.579406   \n",
       "\n",
       "       atributo_6  atributo_7  atributo_8  atributo_9  atributo_10  \\\n",
       "97320    0.295570    0.500035   -0.588367   -0.312699    -0.088776   \n",
       "68107   -1.600090   -1.015530   -1.847722    0.874642     0.937930   \n",
       "59450    2.322294   -0.901188   -0.134448    1.457613    -0.522467   \n",
       "29422    0.380920   -1.480858    0.122126    0.719870    -0.003143   \n",
       "77971    2.424262   -0.345002    0.549287    0.541856     0.810591   \n",
       "\n",
       "       atributo_11  atributo_12  atributo_13  atributo_14  atributo_15  \\\n",
       "97320    -0.902230    -0.094666    -0.707977     0.163998     0.619729   \n",
       "68107    -1.262193    -0.073119    -1.271775    -0.481876     3.446100   \n",
       "59450    -0.333502    -0.436918     0.936369     2.781460    -0.715270   \n",
       "29422     0.191535    -0.098238     0.490150     0.728078    -0.108936   \n",
       "77971    -0.927847    -0.410535     0.229986     2.361430    -0.671067   \n",
       "\n",
       "       atributo_16  atributo_17  atributo_18  atributo_19  predict_proba  \\\n",
       "97320    -0.328969     0.460496    -0.365602    -0.643339       0.169001   \n",
       "68107     0.247052    -1.895841     0.280185     0.953621       0.155998   \n",
       "59450    -0.105945     0.595663     0.704110    -1.123141       0.714071   \n",
       "29422    -0.746725    -0.277786     0.363014     1.634629       0.643472   \n",
       "77971    -0.511379     1.386439    -1.604733    -1.292449       0.667288   \n",
       "\n",
       "       target  \n",
       "97320     0.0  \n",
       "68107     0.0  \n",
       "59450     1.0  \n",
       "29422     0.0  \n",
       "77971     1.0  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"decil\"] = pd.qcut(X_test.predict_proba, q=10, labels = [1,2,3,4,5,6,7,8,9,10], retbins = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decil</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>293.0</td>\n",
       "      <td>2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>219.0</td>\n",
       "      <td>1789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>306.0</td>\n",
       "      <td>1964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>456.0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>747.0</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1673.0</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1660.0</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1702.0</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1747.0</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sum  count\n",
       "decil               \n",
       "1       293.0   2255\n",
       "2       219.0   1789\n",
       "3       306.0   1964\n",
       "4       456.0   2020\n",
       "5       747.0   1996\n",
       "6      1158.0   1978\n",
       "7      1673.0   2002\n",
       "8      1660.0   2006\n",
       "9      1702.0   1992\n",
       "10     1747.0   1998"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.groupby(\"decil\")[\"target\"].agg([\"sum\",\"count\"]) #Atuar de acordo com o decil da probabilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"predict\"] = test_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10510"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[X_test.predict == 1].target.count() #Atuar em todos que o modelo considera 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

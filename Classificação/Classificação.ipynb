{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dummy_classifier.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurando options do pandas para visualização\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.556348</td>\n",
       "      <td>0.380406</td>\n",
       "      <td>-0.373548</td>\n",
       "      <td>0.419505</td>\n",
       "      <td>0.013038</td>\n",
       "      <td>-0.388650</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>-0.299414</td>\n",
       "      <td>0.003877</td>\n",
       "      <td>-0.118151</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>-0.199166</td>\n",
       "      <td>-0.004606</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>-0.210832</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.084875</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>-0.001446</td>\n",
       "      <td>0.501030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.159880</td>\n",
       "      <td>1.437376</td>\n",
       "      <td>1.060570</td>\n",
       "      <td>0.934494</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.030115</td>\n",
       "      <td>0.998353</td>\n",
       "      <td>1.172385</td>\n",
       "      <td>1.003891</td>\n",
       "      <td>0.772854</td>\n",
       "      <td>1.002021</td>\n",
       "      <td>1.225262</td>\n",
       "      <td>1.137065</td>\n",
       "      <td>1.002853</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>1.418103</td>\n",
       "      <td>1.000717</td>\n",
       "      <td>1.299358</td>\n",
       "      <td>1.000113</td>\n",
       "      <td>1.001888</td>\n",
       "      <td>0.500001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-4.823502</td>\n",
       "      <td>-7.334198</td>\n",
       "      <td>-5.213052</td>\n",
       "      <td>-3.900791</td>\n",
       "      <td>-3.657974</td>\n",
       "      <td>-6.030567</td>\n",
       "      <td>-4.366919</td>\n",
       "      <td>-5.981440</td>\n",
       "      <td>-4.388613</td>\n",
       "      <td>-3.705001</td>\n",
       "      <td>-4.104707</td>\n",
       "      <td>-4.990457</td>\n",
       "      <td>-5.826450</td>\n",
       "      <td>-4.517917</td>\n",
       "      <td>-4.289951</td>\n",
       "      <td>-5.662096</td>\n",
       "      <td>-4.403541</td>\n",
       "      <td>-5.197122</td>\n",
       "      <td>-4.137466</td>\n",
       "      <td>-4.434840</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-0.219648</td>\n",
       "      <td>-0.449100</td>\n",
       "      <td>-0.977617</td>\n",
       "      <td>-0.235516</td>\n",
       "      <td>-0.585946</td>\n",
       "      <td>-0.920927</td>\n",
       "      <td>-0.670593</td>\n",
       "      <td>-1.084097</td>\n",
       "      <td>-0.674748</td>\n",
       "      <td>-0.612307</td>\n",
       "      <td>-0.673395</td>\n",
       "      <td>-0.876487</td>\n",
       "      <td>-0.950849</td>\n",
       "      <td>-0.683288</td>\n",
       "      <td>-0.668872</td>\n",
       "      <td>-1.210900</td>\n",
       "      <td>-0.670548</td>\n",
       "      <td>-0.758581</td>\n",
       "      <td>-0.679394</td>\n",
       "      <td>-0.676436</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.444283</td>\n",
       "      <td>0.494584</td>\n",
       "      <td>-0.554817</td>\n",
       "      <td>0.392519</td>\n",
       "      <td>0.027087</td>\n",
       "      <td>-0.277806</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>-0.206833</td>\n",
       "      <td>0.004592</td>\n",
       "      <td>-0.113410</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.070469</td>\n",
       "      <td>-0.118963</td>\n",
       "      <td>-0.005968</td>\n",
       "      <td>0.006223</td>\n",
       "      <td>-0.201436</td>\n",
       "      <td>0.003973</td>\n",
       "      <td>0.117729</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.325171</td>\n",
       "      <td>1.329646</td>\n",
       "      <td>0.294473</td>\n",
       "      <td>0.958363</td>\n",
       "      <td>0.620886</td>\n",
       "      <td>0.284620</td>\n",
       "      <td>0.672774</td>\n",
       "      <td>0.587881</td>\n",
       "      <td>0.684367</td>\n",
       "      <td>0.356457</td>\n",
       "      <td>0.674134</td>\n",
       "      <td>0.847919</td>\n",
       "      <td>0.594264</td>\n",
       "      <td>0.675851</td>\n",
       "      <td>0.680672</td>\n",
       "      <td>0.807538</td>\n",
       "      <td>0.679180</td>\n",
       "      <td>0.938114</td>\n",
       "      <td>0.677689</td>\n",
       "      <td>0.674756</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>5.397826</td>\n",
       "      <td>5.820011</td>\n",
       "      <td>4.882576</td>\n",
       "      <td>5.198659</td>\n",
       "      <td>3.340537</td>\n",
       "      <td>3.977398</td>\n",
       "      <td>4.292186</td>\n",
       "      <td>4.448398</td>\n",
       "      <td>4.367829</td>\n",
       "      <td>2.955692</td>\n",
       "      <td>4.427592</td>\n",
       "      <td>5.535576</td>\n",
       "      <td>3.959930</td>\n",
       "      <td>4.111248</td>\n",
       "      <td>4.178289</td>\n",
       "      <td>5.197292</td>\n",
       "      <td>4.359005</td>\n",
       "      <td>5.574640</td>\n",
       "      <td>4.151129</td>\n",
       "      <td>4.298875</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0              1              2              3  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean        0.556348       0.380406      -0.373548       0.419505   \n",
       "std         1.159880       1.437376       1.060570       0.934494   \n",
       "min        -4.823502      -7.334198      -5.213052      -3.900791   \n",
       "25%        -0.219648      -0.449100      -0.977617      -0.235516   \n",
       "50%         0.444283       0.494584      -0.554817       0.392519   \n",
       "75%         1.325171       1.329646       0.294473       0.958363   \n",
       "max         5.397826       5.820011       4.882576       5.198659   \n",
       "\n",
       "                   4              5              6              7  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean        0.013038      -0.388650       0.001836      -0.299414   \n",
       "std         0.841589       1.030115       0.998353       1.172385   \n",
       "min        -3.657974      -6.030567      -4.366919      -5.981440   \n",
       "25%        -0.585946      -0.920927      -0.670593      -1.084097   \n",
       "50%         0.027087      -0.277806       0.000491      -0.206833   \n",
       "75%         0.620886       0.284620       0.672774       0.587881   \n",
       "max         3.340537       3.977398       4.292186       4.448398   \n",
       "\n",
       "                   8              9             10             11  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean        0.003877      -0.118151       0.000944       0.001801   \n",
       "std         1.003891       0.772854       1.002021       1.225262   \n",
       "min        -4.388613      -3.705001      -4.104707      -4.990457   \n",
       "25%        -0.674748      -0.612307      -0.673395      -0.876487   \n",
       "50%         0.004592      -0.113410       0.000003      -0.070469   \n",
       "75%         0.684367       0.356457       0.674134       0.847919   \n",
       "max         4.367829       2.955692       4.427592       5.535576   \n",
       "\n",
       "                  12             13             14             15  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean       -0.199166      -0.004606       0.003031      -0.210832   \n",
       "std         1.137065       1.002853       0.999316       1.418103   \n",
       "min        -5.826450      -4.517917      -4.289951      -5.662096   \n",
       "25%        -0.950849      -0.683288      -0.668872      -1.210900   \n",
       "50%        -0.118963      -0.005968       0.006223      -0.201436   \n",
       "75%         0.594264       0.675851       0.680672       0.807538   \n",
       "max         3.959930       4.111248       4.178289       5.197292   \n",
       "\n",
       "                  16             17             18             19  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean        0.003085       0.084875       0.001796      -0.001446   \n",
       "std         1.000717       1.299358       1.000113       1.001888   \n",
       "min        -4.403541      -5.197122      -4.137466      -4.434840   \n",
       "25%        -0.670548      -0.758581      -0.679394      -0.676436   \n",
       "50%         0.003973       0.117729       0.003835       0.000451   \n",
       "75%         0.679180       0.938114       0.677689       0.674756   \n",
       "max         4.359005       5.574640       4.151129       4.298875   \n",
       "\n",
       "                  20  \n",
       "count  100000.000000  \n",
       "mean        0.501030  \n",
       "std         0.500001  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         1.000000  \n",
       "75%         1.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vamos comecar olhando descritivas da base, vamos notar que se trata de um dado complexo, com pouco contexto\n",
    "#Esse tipo de dado é complexo para uma pessoa observar e encontrar padrões, por isso modelamos a informação\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    50103\n",
       "0.0    49897\n",
       "Name: 20, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"20\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "target_name = df.columns[-1]\n",
    "print(target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    50103\n",
       "0.0    49897\n",
       "Name: 20, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Baseado na descrição acima, percebemos que a coluna 20 é a unica que contém valores binários (0 ou 1)\n",
    "#Sendo assim ela provavelmente representa nossa target - ou variável resposta\n",
    "df[f\"{target_name}\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando dos dados em conjuntos de treino e teste\n",
    "Vamos dividir nossos dados em dois conjuntos: Treino e Teste.\n",
    "Esse processo é importante para validarmos o processo de modelagem: \n",
    "- Treinamos utilizando o conjunto de <b>Treino</b>\n",
    "- Verificamos as metricas de interesse no conjunto de <b>Teste</b>\n",
    "- Podemos verificar as metricas também no conjunto de Treino com o objetivo de diagnosticar <i>overfitting</i>\n",
    "\n",
    "Para essa separação, podemos utilizar regras simples, como 80% dos dados para treino e 20% para teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop([f\"{target_name}\"],axis=1), #Removemos a target do conjunto de Treino\n",
    "                                                   df[f\"{target_name}\"],# Target\n",
    "                                                   test_size = 0.2 #Costumamos usar regras simples, como 80% treino e 20% teste\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 20) (80000,) (20000, 20) (20000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento dos modelos\n",
    "Utilizaremos o pacote [sklearn](https://scikit-learn.org/stable/) para realizar o treinamento e cálculo das métricas de avaliação.\n",
    "\n",
    "Utilizar esse pacote nos permite seguir uma padronização, que torna a sintaxe bem simples:\n",
    "- .fit(X,y) realiza o treino do modelo\n",
    "- .predict(X) faz a predição do modelo. Em modelos de classificação, a saída será discreta (ex: 0 ou 1)\n",
    "- .predict_proba(X) faz a predição do modelo de forma contínua, ou seja, a probabilidade de pertencer a cada uma das classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Modelo simples utilizando Regressão Logistica\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train) #Treina o modelo\n",
    "\n",
    "train_performance = lr.predict(X_train)\n",
    "test_performance = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando o classification_report para medir performance\n",
    "O método classification_report(y_verdadeiro, y_predito) recebe a predição do modelo (discreta) e os valores reais referentes a essa predição. Com esses valores, conseguimos calcular:\n",
    "- Precision (Precisão): Classificados positivo (1) e realmente positivos, dividido pela quantidade de positivos previstos (o quão bem eu acerto quem eu classifico como positivo?)\n",
    "- Recall (Revocação): Classificados positivo (1) e realmente positivos, dividido pelo total de positivos (Quantos positivos eu acerto no total?)\n",
    "- f1-score: Forma de agregar precisão e recall.\n",
    "\n",
    "Quando vamos calcular essas métricas, devemos definir o que é o positivo para nós. No caso de classificação, costumamos falar que o positivo é quem realiza nosso evento, ou seja, marcados como 1. Utilizando essa perspectiva, devemos observar a linha referente a classe 1 na nossa classification report.\n",
    "\n",
    "Nota: Nada impede de mudarmos o referencial e chamar o positivo de 0, os calculos poderão ser feitos da mesma forma, porém a interpretação será diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.73      0.73     40007\n",
      "         1.0       0.73      0.72      0.72     39993\n",
      "\n",
      "    accuracy                           0.73     80000\n",
      "   macro avg       0.73      0.73      0.73     80000\n",
      "weighted avg       0.73      0.73      0.73     80000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, train_performance)) #Medimos a performance no treino para bsucar overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.73      0.73      9991\n",
      "         1.0       0.73      0.72      0.72     10009\n",
      "\n",
      "    accuracy                           0.72     20000\n",
      "   macro avg       0.72      0.72      0.72     20000\n",
      "weighted avg       0.72      0.72      0.72     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Medimos a performance no teste. Essa é a que vale, pois são dados desconhecidos pelo modelo\n",
    "print(classification_report(y_test, test_performance)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo em árvore, note o padrão sklearn torna a sintaxe semelhante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train,y_train)\n",
    "\n",
    "train_performance = tree.predict(X_train)\n",
    "test_performance = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     39906\n",
      "         1.0       1.00      1.00      1.00     40094\n",
      "\n",
      "    accuracy                           1.00     80000\n",
      "   macro avg       1.00      1.00      1.00     80000\n",
      "weighted avg       1.00      1.00      1.00     80000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, train_performance)) #Sinal de overfitting!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.68      0.68      9991\n",
      "         1.0       0.68      0.69      0.69     10009\n",
      "\n",
      "    accuracy                           0.68     20000\n",
      "   macro avg       0.68      0.68      0.68     20000\n",
      "weighted avg       0.68      0.68      0.68     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_performance)) #Sinal de overfitting!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "train_performance = rf.predict(X_train)\n",
    "test_performance = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98     39906\n",
      "         1.0       0.99      0.98      0.98     40094\n",
      "\n",
      "    accuracy                           0.98     80000\n",
      "   macro avg       0.98      0.98      0.98     80000\n",
      "weighted avg       0.98      0.98      0.98     80000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, train_performance)) #Sinal de Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.80      0.77      9991\n",
      "         1.0       0.78      0.73      0.76     10009\n",
      "\n",
      "    accuracy                           0.77     20000\n",
      "   macro avg       0.77      0.77      0.77     20000\n",
      "weighted avg       0.77      0.77      0.77     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_performance)) #Sinal de Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lidando com Overfitting - Ajuste de Hyperparametros\n",
    "Uma forma comum de lidar com <i>overfitting</i> é ajustando os hyperparametros de forma que controlemos o quanto o modelo consegue se ajustar em nossos dados.\n",
    "\n",
    "O <i>overfitting</i> normalmente é causado por uma complexidade do modelo, em modelos de árvore isso quer dizer:\n",
    "- Muitos estimadores (muitas árvores): Em modelos de ensemble, adicionar muitos modelos pode não agregar na previsão resultante. Muitos modelos identicos podem gerar um viés e causar <i>overfitting</i>\n",
    "- Árvores muito profundas: Cada nível de profundidade da árvore cria uma regra nova para separar nossos dados, ou seja, cada folha possui menos amostras a cada nível que crescemos a árvore. Sendo assim, em treino, regras que afetam poucas amostras são muito especificas, portanto podem estar muito vínculadas ao conjunto de treino e não generalizar.\n",
    "\n",
    "Uma forma comum de fazer a busca dos melhores hyperparametros é através do Grid Search (Busca em grade).\n",
    "- Montamos uma grade contendo os hyperparametros de interesse e os respectivos valores.\n",
    "- O algoritmo vai separar a nossa base em \"mini conjuntos\" de treino e teste para testar cada combinação da grade\n",
    "- A melhor combinação (a que maximizar o acerto) será a escolhida.\n",
    "\n",
    "Exemplo: Vamos testar uma RandomForest com 10 e 20 árvores, onde cada árvore pode ter profundidade máxima de 3 ou 4. Sendo assim, temos:\n",
    "\n",
    "|iteração|árvores|profundidade|\n",
    "| ------------- |:-------------:| -----:|\n",
    "|1|10|3|\n",
    "|2|20|3|\n",
    "|3|10|4|\n",
    "|4|20|4|\n",
    "\n",
    "Supondo que vamos separar nossos dados em 3 subconjuntos A, B e C para testar cada combinação:\n",
    "Na iteração 1 teremos\n",
    "\n",
    "|Conjunto de treino|Conjunto de Teste|Acerto (%)|\n",
    "| ------------- |:-------------:| -----:|\n",
    "|A+B|C|80|\n",
    "|A+C|B|90|\n",
    "|B+C|A|95|\n",
    "\n",
    "Sendo assim, essa estratégia da iteração 1 possui um acerto médio de 88.3%. Repetimos o processo até encontrar a melhor combinação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 20)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] max_depth=2, n_estimators=5 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... max_depth=2, n_estimators=5, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=5 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... max_depth=2, n_estimators=5, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=5, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=10, total=   0.4s\n",
      "[CV] max_depth=2, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=10, total=   0.5s\n",
      "[CV] max_depth=2, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=10, total=   0.4s\n",
      "[CV] max_depth=2, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=20, total=   0.9s\n",
      "[CV] max_depth=2, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=20, total=   0.8s\n",
      "[CV] max_depth=2, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=20, total=   0.9s\n",
      "[CV] max_depth=3, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=5, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=5, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=5, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=10, total=   0.6s\n",
      "[CV] max_depth=3, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=10, total=   0.6s\n",
      "[CV] max_depth=3, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=10, total=   0.6s\n",
      "[CV] max_depth=3, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=20, total=   1.2s\n",
      "[CV] max_depth=3, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=20, total=   1.1s\n",
      "[CV] max_depth=3, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=20, total=   1.1s\n",
      "[CV] max_depth=4, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=5, total=   0.4s\n",
      "[CV] max_depth=4, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=5, total=   0.4s\n",
      "[CV] max_depth=4, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=5, total=   0.4s\n",
      "[CV] max_depth=4, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=10, total=   0.8s\n",
      "[CV] max_depth=4, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=10, total=   0.8s\n",
      "[CV] max_depth=4, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=10, total=   0.7s\n",
      "[CV] max_depth=4, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=20, total=   1.4s\n",
      "[CV] max_depth=4, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=20, total=   1.5s\n",
      "[CV] max_depth=4, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=20, total=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   18.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=10, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [2, 3, 4], 'n_estimators': [5, 10, 20]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_rf = {\n",
    "            \"n_estimators\":[5,10,20], #Regular o número de estimadores\n",
    "            \"max_depth\":[2,3,4] #Regular a profundidade das árvores\n",
    "          }\n",
    "gs = GridSearchCV(rf, #Objeto do classificador sklearn\n",
    "                  param_grid = dict_rf, #Dicionario de hyperparametros\n",
    "                  cv = 3, #Validação cruzada - vezes que o algoritmo vai separar o nosso dado e testar\n",
    "                  verbose = 2 #Apenas para vermos o que está acontecendo (print de textos na tela)\n",
    "                 )\n",
    "\n",
    "gs.fit(X_train,y_train) #Fit do objeto GS, uma RF será treinada com cada uma das combinações de hyperparametros do dicionario para cada valor do CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gs = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_performance = rf_gs.predict(X_test)\n",
    "train_performance = rf_gs.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.78      0.77     39906\n",
      "         1.0       0.78      0.74      0.76     40094\n",
      "\n",
      "    accuracy                           0.76     80000\n",
      "   macro avg       0.76      0.76      0.76     80000\n",
      "weighted avg       0.76      0.76      0.76     80000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, train_performance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.78      0.76      9991\n",
      "         1.0       0.77      0.74      0.75     10009\n",
      "\n",
      "    accuracy                           0.76     20000\n",
      "   macro avg       0.76      0.76      0.76     20000\n",
      "weighted avg       0.76      0.76      0.76     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_performance)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
